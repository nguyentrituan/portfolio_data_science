# PORTFOLIO DATA SCIENCE 
# A/B Testing

In my experience working at leading tech companies, I've noticed that A/B testing is widely used, especially in companies and industries with large user bases such as e-commerce and gaming.

Why use A/B testing? With a large user base, companies cannot simply apply any feature they want, as doing so may carry the risk of hurting user experience and subsequently affecting the lifetime value of users. Therefore, A/B testing is necessary to control risks. Instead of applying changes to the entire user base, companies can apply them to a small group, for example, about 10% of users, and then use statistical methods to determine if there is a statistically significant difference between the control group and the variants.

In terms of methodology, I have documented it in this [Gitbook Link](https://app.gitbook.com/o/VfRPaxLWrwVO1zxPDj2s/s/iggGa4mab2uKFxO1Zj5M/). On GitHub, I provide code for both frequentist and Bayesian approaches in A/B testing.

Files consist of the following parts:
1. Frequentist Code
2. Bayesian Code

![image](https://github.com/nguyentrituan/portfolio_data_science/assets/121095339/59bb93a6-e043-41b7-ba45-e98128be6b99)


# Kaggle Competition - Prediction Interval for Birth Weight

I have a change to participate in Kaggle Competion, and we được top 10 trong bảng xếp hạng leaderboard.

Kaggle Competition Info https://www.kaggle.com/competitions/prediction-interval-competition-i-birth-weight/overview

Trong cuộc thi tôi đã sử dụng nhiều thuật tonas khác nhau từ đơn giản đến phức tạp để tune model các model gồm:
KNN, Linear Regression, Xgboost Regressor, Decision Tree, Random Forrest. Kết quả cho thấy Model về Xgboost cho kết quả tốt nhất.

Note:
XGBoost is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework. In prediction problems involving unstructured data (images, text, etc.) artificial neural networks tend to outperform all other algorithms or frameworks. However, when it comes to small-to-medium structured/tabular data, decision tree based algorithms are considered best-in-class right now. XGBoost and Gradient Boosting Machines (GBMs) are both ensemble tree methods that apply the principle of boosting weak learners (CARTs generally) using the gradient descent architecture. However, XGBoost improves upon the base GBM framework through systems optimization and algorithmic enhancements.

![image](https://github.com/nguyentrituan/portfolio_data_science/assets/121095339/e17796bd-3fc9-48fc-bd90-fbfedf4a7793)


# Machine Learning for Marketing

Đây là khoá học mà tôi được cấp chứng chỉ tại Trung Tâm tin học Đại học Khoa học tự nhiên

Nó bảo gồm rất nhiều Model về Machine Learning, đặc biệt có chứa phần thi tốt nghiệp của tôi trong khoá học

# Segmentation

Bao gồm 3 cách segmentation gồm K-means, Cohort view và RFM

